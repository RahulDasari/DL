{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.plot_utils import *\n",
    "def learn(agent):\n",
    "    agent.train(1000)\n",
    "    plot_episode_rewards(agent.episode_rewards, 'BipedalWalker: Episode Rewards - Training')\n",
    "    plt.show()\n",
    "    plot_actor_critic_losses(agent.actor_losses, agent.critic_losses)\n",
    "    plt.show()\n",
    "    agent.save_model_weights(\"bipedalwalker\", \"td3\")\n",
    "\n",
    "def test(agent):\n",
    "    agent.test(10)\n",
    "    plot_episode_rewards(agent.test_rewards, 'BipedalWalker: Episode Rewards - Testing')\n",
    "    plt.show()\n",
    "    # agent.save_plot_data(\"highway\", \"ddpg\", \"test_rewards\", agent.test_rewards)\n",
    "\n",
    "def visualize(agent, env):\n",
    "    agent.change_environment(env)\n",
    "    agent.visualize(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from td3.td3 import td3\n",
    "\n",
    "params = {\n",
    "    'gamma': 0.99,              # discount factor\n",
    "    'alpha_critic': 0.0001,     # learning rate for critic net\n",
    "    'alpha_actor': 0.001,       # learning rate for actor network\n",
    "    'buffer_size': 10000,       # Size of Replay Buffer\n",
    "    'batch_size' : 100,         # Mini Batch Size for Back Prop\n",
    "    'tau':         0.001,       # Percentage of new values to update target network with\n",
    "    'update_rate': 100,         # Update network every n steps\n",
    "    'noise_scale' : 0.1,        # Standard Deviation of Gausian Noise\n",
    "    \"actor_update_frequency\": 2,# How often to update the actor network, every n updates\n",
    "}\n",
    "\n",
    "env = gym.make(\"BipedalWalker-v3\")\n",
    "agent = td3(env, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill buffer\n",
    "state, info = env.reset()\n",
    "for _ in range(10000):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    agent.buffer.add(state, action, reward, next_state, terminated)\n",
    "    state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(agent.noise_arr)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Noise Value')\n",
    "plt.title('Noise for TD3 Algorithm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.plot_utils import *\n",
    "# plot_data = load_plot_data(\"pendulum\", \"td3\", \"plot_data\")\n",
    "plot_dict = {\n",
    "        \"episode_rewards\" : agent.episode_rewards,\n",
    "        \"actor_losses\"    : agent.actor_losses,\n",
    "        \"critic_losses\"   : agent.critic_losses,\n",
    "        \"test_rewards\"    : agent.test_rewards\n",
    "    }\n",
    "save_plot_data(\"ant\", \"td3\", \"plot_data\", plot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env =  gym.make(\"BipedalWalker-v3\", render_mode='human')\n",
    "visualize(agent, env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
